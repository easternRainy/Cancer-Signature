{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import *\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerDataset(Dataset):\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, df_X, df_y):\n",
    "        \n",
    "        \n",
    "        self.data_list = torch.FloatTensor(df_X.values)\n",
    "        \n",
    "        if df_y is not None:\n",
    "            assert len(df_X) == len(df_y)\n",
    "            self.target_list = torch.LongTensor(df_y.values)\n",
    "        else:\n",
    "            df_y = np.zeros(len(df_X)) * (-1)\n",
    "            self.target_list = torch.LongTensor(df_y)\n",
    "        \n",
    "        assert(len(self.data_list) == len(self.target_list))\n",
    "      \n",
    "    # return the length of dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    # return the key-th element of dataset\n",
    "    def __getitem__(self, key):\n",
    "        \n",
    "        return self.data_list[key], self.target_list[key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, hidden_size, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, hidden_size)\n",
    "#         self.layer_2 = nn.Linear(hidden_size, 10)\n",
    "# #         self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(hidden_size, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "#         self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        self.soft_max = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        \n",
    "#         x = self.layer_2(x)\n",
    "#         x = self.batchnorm2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = self.layer_3(x)\n",
    "#         x = self.batchnorm3(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict_prob(self, inputs):\n",
    "        \"\"\"\n",
    "        call self.forward, then calculate softmax to get the probability\n",
    "        \"\"\"\n",
    "        out = self.forward(inputs)\n",
    "        out = self.soft_max(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        hard predict, call predict_prob, then get the max index\n",
    "        \"\"\"\n",
    "        out = self.predict_prob(inputs)\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerPredictor(nn.Module):\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, input_size, hidden_size, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.input_relu = nn.ReLU()\n",
    "        self.hidden_linear = nn.Linear(hidden_size, n_class)\n",
    "        \n",
    "        # do not use in forward, but use in predict\n",
    "        self.soft_max = nn.Softmax(dim=-1)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out = None\n",
    "        out = self.input_layer(inputs)\n",
    "        out = self.input_relu(out)\n",
    "        out = self.hidden_linear(out)\n",
    "        out = self.input_relu(out)\n",
    "        \n",
    "        ## We do not compute soft max directly\n",
    "        ## But combine it with loss. Because F.cross_entropy \n",
    "        ## Will compute soft max\n",
    "        # out = self.soft_max(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def predict_prob(self, inputs):\n",
    "        \"\"\"\n",
    "        call self.forward, then calculate softmax to get the probability\n",
    "        \"\"\"\n",
    "        out = self.forward(inputs)\n",
    "        out = self.soft_max(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        hard predict, call predict_prob, then get the max index\n",
    "        \"\"\"\n",
    "        out = self.predict_prob(inputs)\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    # constructor\n",
    "    def __init__(self,  model, criterion, optimizer):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "       \n",
    "        \n",
    "    def train(self, train_loader, valid_loader, device, num_epochs, early_stop_patience=5, print_log=True):\n",
    "        self.early_stop_patience = early_stop_patience\n",
    "        no_improve = 0\n",
    "        \n",
    "        train_loss_history = []\n",
    "        valid_loss_history = []\n",
    "        \n",
    "        min_loss = np.Infinity\n",
    "        for epoch in tqdm.notebook.tqdm(range(num_epochs)):\n",
    "            \n",
    "            train_loss_epoch = []\n",
    "            valid_loss_epoch = []\n",
    "            \n",
    "            self.model.train()\n",
    "\n",
    "            for i, (data_batch, target_batch) in enumerate(train_loader):\n",
    "                preds = self.model(data_batch.to(device))\n",
    "                train_loss = self.criterion(preds, target_batch.to(device))\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                train_loss_epoch.append(train_loss.item())\n",
    "            \n",
    "            batch_min_loss = np.Infinity\n",
    "            self.model.eval()\n",
    "            for i, (data_batch, target_batch) in enumerate(valid_loader):\n",
    "                preds = self.model(data_batch.to(device))\n",
    "                valid_loss = criterion(preds, target_batch.to(device))\n",
    "                optimizer.zero_grad()\n",
    "                valid_loss_epoch.append(valid_loss.item())\n",
    "                    \n",
    "                if valid_loss < batch_min_loss:\n",
    "                    batch_min_loss = valid_loss\n",
    "                    \n",
    "                \n",
    "            \n",
    "            mean_train_loss_epoch = np.mean(train_loss_epoch)\n",
    "            mean_valid_loss_epoch = np.mean(valid_loss_epoch)\n",
    "            \n",
    "            train_loss_history.append(mean_train_loss_epoch)\n",
    "            valid_loss_history.append(mean_valid_loss_epoch)\n",
    "            \n",
    "            if batch_min_loss < min_loss:\n",
    "                no_improve = 0\n",
    "                min_loss = batch_min_loss\n",
    "                torch.save(model, 'best_model.pt')\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve > self.early_stop_patience:\n",
    "                    print(f\"Early Stop at epoch {epoch}\")\n",
    "                    break\n",
    "                \n",
    "            if print_log:\n",
    "                print(f\"Epoch: {epoch}, train_loss: {mean_train_loss_epoch},\\\n",
    "                        valid_loss: {mean_valid_loss_epoch}\")\n",
    "        \n",
    "        return train_loss_history, valid_loss_history\n",
    "    \n",
    "    def do_test(self, test_loader, device, best_model=None):\n",
    "        if best_model == None:\n",
    "            best_model = self.model\n",
    "            \n",
    "        real_data = []\n",
    "        pred_data = []\n",
    "        best_model.eval()\n",
    "        \n",
    "        for i, (data_batch, target_batch) in enumerate(test_loader):\n",
    "            preds = best_model.predict(data_batch.to(device))\n",
    "            # test_loss = self.criterion(preds, target_batch.to(device))\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for i in range(len(target_batch)):\n",
    "                \n",
    "                real_data.append(target_batch[i].item())\n",
    "                pred_data.append(preds[i].item())\n",
    "        \n",
    "        return np.array(real_data), np.array(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_ml2_2021.csv')\n",
    "X = df.drop(columns=['target', 'problem_id'])\n",
    "y = df.target\n",
    "df_test = pd.read_csv('test0.csv', index_col='obs_id').drop(columns=['problem_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df_test.drop(columns='target'), df_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights(dataset):\n",
    "    X = dataset.data_list\n",
    "    Y = dataset.target_list\n",
    "    nclasses = Y.unique(return_counts=True)[1] / Y.shape[0]\n",
    "    \n",
    "    return torch.DoubleTensor([nclasses[y] for y in Y])\n",
    "\n",
    "train_dataset = CancerDataset(X_train, y_train)\n",
    "valid_dataset = CancerDataset(X_val, y_val)\n",
    "test_dataset = CancerDataset(df_test.drop(columns='target'), df_test.target)\n",
    "\n",
    "weights = make_weights(train_dataset)\n",
    "sampler = WeightedRandomSampler(weights, len(weights))                     \n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda: 5\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# ax.plot(train_log, label=\"train_loss\")\n",
    "# ax.plot(valid_log, label=\"valid_loss\")\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, input_size = X.shape\n",
    "# hidden_size = 100\n",
    "n_class = len(y.unique())\n",
    "criterion = F.cross_entropy\n",
    "lr = 0.001\n",
    "nb_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [180, 200, 220]\n",
    "# hidden_sizes = [21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c197057982f430c94f77afafdcaee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at epoch 26\n",
      "hidden size: 180, train accuracy: 0.9430808613160668, valid accuracy: 0.6682721252257676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2603aa3cc0e4b429ae0c5c227147b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at epoch 26\n",
      "hidden size: 200, train accuracy: 0.8944436078903779, valid accuracy: 0.6435881998795906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5425db1bc18d40979c61369850a728d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at epoch 29\n",
      "hidden size: 220, train accuracy: 0.9591928926366511, valid accuracy: 0.6604455147501506\n"
     ]
    }
   ],
   "source": [
    "for hidden_size in hidden_sizes:\n",
    "#     model = CancerPredictor(input_size, hidden_size, n_class)\n",
    "    model = MulticlassClassification(input_size, hidden_size, n_class)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    learner = Learner(model, criterion, optimizer)\n",
    "    \n",
    "    train_log, valid_log = learner.train(train_loader, valid_loader, \\\n",
    "                                         device, nb_epoch, early_stop_patience=20, \\\n",
    "                                         print_log=False)\n",
    "    \n",
    "    best_model = torch.load(\"best_model.pt\")\n",
    "    y_real_train, y_pred_train = learner.do_test(train_loader, device, best_model=best_model)\n",
    "    y_real_valid, y_pred_valid = learner.do_test(valid_loader, device, best_model=best_model)\n",
    "    # y_real_test, y_pred_test = learner.do_test(test_loader, device, best_model=best_model)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_real_train, y_pred_train)\n",
    "    valid_accuracy = accuracy_score(y_real_valid, y_pred_valid)\n",
    "    # test_accuracy = accuracy_score(y_real_test, y_pred_test)\n",
    "    \n",
    "\n",
    "#     train_accuracy = balanced_accuracy_score(y_real_train, y_pred_train)\n",
    "#     valid_accuracy = balanced_accuracy_score(y_real_valid, y_pred_valid)\n",
    "    \n",
    "    print(f\"hidden size: {hidden_size}, train accuracy: {train_accuracy}, valid accuracy: {valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32057d7a03f49098def33bd93406227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stop at epoch 29\n",
      "hidden size: 200, train accuracy: 0.9727450685137781, valid accuracy: 0.679108970499699\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-df70b0bd94a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"hidden size: {hidden_size}, train accuracy: {train_accuracy}, valid accuracy: {valid_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.66\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "while valid_accuracy < 0.66:\n",
    "    hidden_size = 200\n",
    "#     model = CancerPredictor(input_size, hidden_size, n_class)\n",
    "    model = MulticlassClassification(input_size, hidden_size, n_class)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    learner = Learner(model, criterion, optimizer)\n",
    "    \n",
    "    train_log, valid_log = learner.train(train_loader, valid_loader, \\\n",
    "                                         device, nb_epoch, early_stop_patience=20, \\\n",
    "                                         print_log=False)\n",
    "    \n",
    "    best_model = torch.load(\"best_model.pt\")\n",
    "    y_real_train, y_pred_train = learner.do_test(train_loader, device, best_model=best_model)\n",
    "    y_real_valid, y_pred_valid = learner.do_test(valid_loader, device, best_model=best_model)\n",
    "    # y_real_test, y_pred_test = learner.do_test(test_loader, device, best_model=best_model)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_real_train, y_pred_train)\n",
    "    valid_accuracy = accuracy_score(y_real_valid, y_pred_valid)\n",
    "    # test_accuracy = accuracy_score(y_real_test, y_pred_test)\n",
    "    \n",
    "\n",
    "#     train_accuracy = balanced_accuracy_score(y_real_train, y_pred_train)\n",
    "#     valid_accuracy = balanced_accuracy_score(y_real_valid, y_pred_valid)\n",
    "    \n",
    "    print(f\"hidden size: {hidden_size}, train accuracy: {train_accuracy}, valid accuracy: {valid_accuracy}\")\n",
    "    \n",
    "    if valid_accuracy >= 0.66:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(\"best_model_save.pt\")\n",
    "y_real_train, y_pred_train = learner.do_test(train_loader, device, best_model=best_model)\n",
    "y_real_valid, y_pred_valid = learner.do_test(valid_loader, device, best_model=best_model)\n",
    "y_real_test, y_pred_test = learner.do_test(test_loader, device, best_model=best_model)\n",
    "\n",
    "train_accuracy = accuracy_score(y_real_train, y_pred_train)\n",
    "valid_accuracy = accuracy_score(y_real_valid, y_pred_valid)\n",
    "# test_accuracy = accuracy_score(y_real_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.679108970499699"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_id  target\n",
       "0       0       0\n",
       "1       1       0\n",
       "2       2       0\n",
       "3       3       0\n",
       "4       4       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2041"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obs_id\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2041"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"target\"] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_id  target\n",
       "0        0       1\n",
       "1        1       0\n",
       "2        2       0\n",
       "3        3       0\n",
       "4        4       1\n",
       "5        5       0\n",
       "6        6       0\n",
       "7        7       1\n",
       "8        8       1\n",
       "9        9       1\n",
       "10      10       0\n",
       "11      11       0\n",
       "12      12       1\n",
       "13      13       1\n",
       "14      14       0\n",
       "15      15       1\n",
       "16      16       1\n",
       "17      17       1\n",
       "18      18       1\n",
       "19      19       1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
