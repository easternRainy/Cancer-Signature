{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced ML Kaggle Using sklearn\n",
    "Sicheng Zhou, Flora Chen, University of San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score \n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could we build a model to predict the probability that a credit card customer is going to churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the [dataset](https://www.kaggle.com/sakshigoyal7/credit-card-customers). This dataset contains 10,127 customers' information including age, salary, etc. There are 1627 Customers who have churned. Other 8500 customers are not churned. So this is a very unbalanced dataset. If we set a baseline model predicting every customer as not churned, there is 83.9% to be right. As as result, our model must beat that baseline.\n",
    "\n",
    "Fortunately, the data has no missing values. There are 19 feature columns and 1 target column. Among the features columns, there are 5 categorical columns: Gender, Educational_Level, Martial_Status, Income_Category, and Card_Category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_ml2_2021.csv')\n",
    "X = df.drop(columns=['target', 'problem_id'])\n",
    "y = df.target\n",
    "df_test = pd.read_csv('test0.csv', index_col='obs_id').drop(columns=['problem_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, stratify=y, random_state=1)\n",
    "X_test, y_test = df_test.drop(columns='target'), df_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already set a baseline model predicting every customer as not churned, there is 83.9% to be right. However, this dataset is hight unbalanced. We want to fit another baseline model without balancing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipe = make_pipeline(\n",
    "    LogisticRegression(\n",
    "        solver='liblinear',\n",
    "        class_weight=None\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('logisticregression', LogisticRegression(solver='liblinear'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pipe.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred = base_pipe.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33029955483826184"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_accuracy = balanced_accuracy_score(y_val, base_pred)\n",
    "base_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.588199879590608"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, base_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used balanced_accuracy_score for the classifier, we must also calculate a balanced accuracy score for the first baseline model predicting everything as \"not churned\", that is, 0. According to sklearn official documentation, \n",
    ">The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our baseline Logistic Classifier performs better than simply predicting everything to be 0. Next, we will deal with the imbalancing dataset to see if we could get better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to deal with imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes we could simply ignore class imbalances because most real-world data is imbalanced. Small differences at larget scale might not effect business outcomes. If the imbalance is not serious, we could ignore it. However, in this project, the imbalance of data could not be ignored.\n",
    "- We could get more data for the minority group. \n",
    "- The most practical way in this project is to resample the data. For example, over-sample minority group, under-sample majority group, representative sampling of both groups and synthetically generate samples from minority class(SMOTE). In this project, we use SMOTE. SMOTE synthesises new minority instances between existing minority instances. In the intuitive picture below, SMOTE synthetic minority instances somewhere on these lines.\n",
    "- We should pick an appropriate evaluation metrics, especially avoiding accuracy. We could apply balanced_accuracy_score in this project.\n",
    "- Use robust algorithms. For example, Support Vector Machine, which finds a hyperplan that maximizes the margin. We only needs very few \"support vectors\" thus minimizing the impact of imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/rikunert/SMOTE_visualisation/master/SMOTE_R_visualisation_2.png)\n",
    "\n",
    "image from: https://rikunert.com/SMOTE_explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "#     LogisticRegression(),\n",
    "#     RidgeClassifier(),\n",
    "#     SGDClassifier(),\n",
    "#     SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    ExtraTreesClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_4_model(model):\n",
    "    pipe_4_model = make_pipeline(   \n",
    "        \n",
    "        imblearn.over_sampling.SMOTE(k_neighbors=10),\n",
    "        model\n",
    "    )\n",
    "    return pipe_4_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [pipe_4_model(model) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We could use pipes[index].get_params().keys() to get model names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for LogisticRegression model, we set l1_ratio to find a mid-point\n",
    "# between l1 and l2 regularization\n",
    "lr_params = dict(\n",
    "    logisticregression__penalty=['elasticnet'],\n",
    "    logisticregression__solver=['saga'],\n",
    "    logisticregression__l1_ratio=[0, 0,1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for RidgeClassifier, alpha is important for regularization\n",
    "rc_params = dict(\n",
    "    ridgeclassifier__alpha=[0.1, 1, 10, 100, 1000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for SGDClassifier, l1_ratio still controls the balance\n",
    "# between l1 and l2 regularization\n",
    "# We should set early stoppint as True to prevent overfitting\n",
    "sgd_params = dict(\n",
    "    \n",
    "    sgdclassifier__l1_ratio=[0, 0,1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "    sgdclassifier__early_stopping=[True],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Support Vector Machine, the kernel is important\n",
    "# different kernel defines different method to transform data\n",
    "svc_params = dict(\n",
    "    svc__C=[0.1, 0.3, 0.5, 1, 10, 100],\n",
    "    svc__kernel=['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    svc__gamma=[0.1, 1, 10, 100, 1000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for RandomForestClassifier, n_estimators is the number of decision trees\n",
    "# if n_estimator is high, it tends to overfitting\n",
    "# max_depth is the max depth of each tree, if high, it tends to overfitting\n",
    "# max_feature is the max features each tree use. We do not use all the features \n",
    "# to prevent overfitting\n",
    "rfc_params = dict(\n",
    "    randomforestclassifier__n_estimators=[70, 80, 90, 100, 110, 120, 130, 140],\n",
    "    randomforestclassifier__max_depth=[8, 20, 22, 30, 50],\n",
    "    randomforestclassifier__max_features=[500, 600, 700]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for AdaBoostClassifier, n_estimators is still the number of estimators\n",
    "abc_params = dict(\n",
    "    adaboostclassifier__n_estimators=[10, 20, 30, 40, 50, 70, 100, 500, 1000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ExtraTreesClassifier, n_estimators is still the number of estimators\n",
    "# n_depth is the maximum depth of the tree\n",
    "et_params = dict(\n",
    "    extratreesclassifier__n_estimators = [5, 10, 50, 100, 200, 300, 400, 500],\n",
    "    extratreesclassifier__max_depth = [range(2,30), None],\n",
    "    extratreesclassifier__min_samples_split = range(1,10),\n",
    "    extratreesclassifier__min_samples_leaf = range(1,10),\n",
    "    extratreesclassifier__max_features = ['auto', 'sqrt', 'log2'],\n",
    "    extratreesclassifier__warm_start = [True, False],   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "#     lr_params,\n",
    "#     rc_params,\n",
    "#     sgd_params,\n",
    "#     svc_params,\n",
    "    rfc_params,\n",
    "    abc_params,\n",
    "    et_params\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Parameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use Randomized Search strategy to select the best model. Usually this strategy is faster than Grid Search. \n",
    "- We use cross validation with 3 folds. \n",
    "- We use different metrics: balanced_accuracy_score and f1 score. Both of them are suitable in a unbalanced dataset.\n",
    "- balanced_accuracy_score gives the accuracy.\n",
    "- f1 score gives the harmonic average of precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_scorer = make_scorer(balanced_accuracy_score)\n",
    "accuracy_scorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = []\n",
    "best_params = []\n",
    "best_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=0, RandomForestClassifier: 0.3426374678944292, metrics=balanced_accuracy_score\n",
      "index=1, AdaBoostClassifier: 0.31884723713513535, metrics=balanced_accuracy_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhousicheng/Projects/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.35494121 0.2661889         nan        nan 0.24791442]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=2, ExtraTreesClassifier: 0.3549412102432132, metrics=balanced_accuracy_score\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(models)):\n",
    "    for score in [balanced_scorer]:\n",
    "        model_family = models[index].__class__.__name__\n",
    "        pipe = pipes[index]\n",
    "        search_space = params[index]\n",
    "\n",
    "        cross_valid = RandomizedSearchCV(\n",
    "            estimator = pipe,\n",
    "            param_distributions = search_space,\n",
    "            n_iter = 5,\n",
    "            cv = 3,\n",
    "            scoring = score,\n",
    "            n_jobs = -1,\n",
    "            verbose = -1\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "        best_model = cross_valid.fit(X.values, y.values)\n",
    "        best_param = cross_valid.best_params_\n",
    "        best_score = cross_valid.best_score_\n",
    "\n",
    "        best_models.append(best_model)\n",
    "        best_params.append(best_param)\n",
    "        best_scores.append(best_score)\n",
    "\n",
    "        print(f\"index={index}, {model_family}: {best_score}, metrics={score._score_func.__name__}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the training process above, the best model should be RandomForestClassifier, for both balanced_accuracy_score and f1_score.\n",
    "- Here are the parameters of random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'extratreesclassifier__warm_start': False, 'extratreesclassifier__n_estimators': 300, 'extratreesclassifier__min_samples_split': 8, 'extratreesclassifier__min_samples_leaf': 9, 'extratreesclassifier__max_features': 'sqrt', 'extratreesclassifier__max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "print(best_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe = make_pipeline(   \n",
    "    imblearn.over_sampling.SMOTE(k_neighbors=13),\n",
    "    ExtraTreesClassifier(\n",
    "        n_estimators = 250,\n",
    "        min_samples_split = 8,\n",
    "        min_samples_leaf = 9,\n",
    "        max_features = 'sqrt',\n",
    "        max_depth = None\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=13)),\n",
       "                ('extratreesclassifier',\n",
       "                 ExtraTreesClassifier(max_features='sqrt', min_samples_leaf=9,\n",
       "                                      min_samples_split=8, n_estimators=250))])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipe.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred = best_pipe.predict(X_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6827212522576761"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val.values, best_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_pipe.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "submission[\"target\"] = y_pred_test\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
